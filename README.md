# Interpretability-Hackathon
This repo contains the report and code that I created during Apart Research's Interpretability Hackathon (11/11/2022 - 13/11/2022). It incorporates significant threads of work conducted by Neel Nanda and Redwood Research. I would like to sincerely thank them for the wealth of resources they’ve provided in support of mechanistic interpretability research. Additionally, I would like to sincerely thank Apart Research for hosting such an enjoyable hackathon.

**Resources used:**
* Kevin Wang, Alexandre Variengien, Arthur Conmy, Buck Shlegeris, Jacob Steinhardt: “Interpretability in the Wild: a Circuit for Indirect Object Identification in GPT-2 small”, 2022; arXiv:2211.00593.
* Neel Nanda: “SERI_MATS_IOI_Demo”, 2022; https://colab.research.google.com/drive/1mL4KlTG7Y8DmmyIlE26VjZ0mofdCYVW6
* Stanford University. “Mistral”, 2022. https://github.com/stanford-crfm/mistral
* Neel Nanda: “Easy Transformer Demo”, 2022: https://colab.research.google.com/github/neelnanda-io/Easy-Transformer/blob/main/EasyTransformer_Demo.ipynb
* Redwood Research: “Easy Transformer”, 2022: https://github.com/redwoodresearch/Easy-Transformer
* Neel Nanda: “Easy Transformer”, 2022: https://github.com/neelnanda-io/Easy-Transformer 
